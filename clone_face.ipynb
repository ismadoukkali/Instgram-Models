{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dulceida Instagram picture generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "API_KEY = \"fbd6be32-1480-4fd1-8c5d-dfb329ec4dfc\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "IMAGES = [\n",
    "    \"https://cdn.ondavasca.com/dulceida.jpg\",\n",
    "    \"https://imagenes.elpais.com/resizer/7opV7Iza_O7x3Rix9UvA0RvysQE=/1960x1470/arc-anglerfish-eu-central-1-prod-prisa.s3.amazonaws.com/public/BUZ7C32TVOWLA6DGLRLIVU63IM.jpg\",\n",
    "    \"https://cdn.semana.es/wp-content/uploads/2023/03/semana-dulceida-se-moja-sobre-la-polemica-de-los-premios-idolo-y-el-planton-de-influencers-a-ultima-hora.jpg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(title):\n",
    "    url = \"https://api.tryleap.ai/api/v1/images/models\"\n",
    "\n",
    "    payload = {\n",
    "        \"title\": title,\n",
    "        \"subjectKeyword\": \"@me\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=HEADERS)\n",
    "\n",
    "    model_id = json.loads(response.text)[\"id\"]\n",
    "    return model_id\n",
    "\n",
    "\n",
    "def upload_image_samples(model_id):\n",
    "    url = f\"https://api.tryleap.ai/api/v1/images/models/{model_id}/samples/url\"\n",
    "\n",
    "    payload = {\"images\": IMAGES}\n",
    "    response = requests.post(url, json=payload, headers=HEADERS)\n",
    "\n",
    "\n",
    "def queue_training_job(model_id):\n",
    "    url = f\"https://api.tryleap.ai/api/v1/images/models/{model_id}/queue\"\n",
    "    response = requests.post(url, headers=HEADERS)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "    version_id = data[\"id\"]\n",
    "    status = data[\"status\"]\n",
    "\n",
    "    print(f\"Version ID: {version_id}. Status: {status}\")\n",
    "\n",
    "    return version_id, status\n",
    "\n",
    "\n",
    "def get_model_version(model_id, version_id):\n",
    "    url = f\"https://api.tryleap.ai/api/v1/images/models/{model_id}/versions/{version_id}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    version_id = data[\"id\"]\n",
    "    status = data[\"status\"]\n",
    "\n",
    "    print(f\"Version ID: {version_id}. Status: {status}\")\n",
    "\n",
    "    return version_id, status\n",
    "\n",
    "\n",
    "def generate_image(model_id, prompt):\n",
    "    url = f\"https://api.tryleap.ai/api/v1/images/models/{model_id}/inferences\"\n",
    "\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"steps\": 50,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": 4523184\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=HEADERS)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    inference_id = data[\"id\"]\n",
    "    status = data[\"status\"]\n",
    "\n",
    "    print(f\"Inference ID: {inference_id}. Status: {status}\")\n",
    "\n",
    "    return inference_id, status\n",
    "\n",
    "\n",
    "def get_inference_job(model_id, inference_id):\n",
    "    url = f\"https://api.tryleap.ai/api/v1/images/models/{model_id}/inferences/{inference_id}\"\n",
    "\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    inference_id = data[\"id\"]\n",
    "    state = data[\"state\"]\n",
    "    image = None\n",
    "\n",
    "    if len(data[\"images\"]):\n",
    "        image = data[\"images\"][0][\"uri\"]\n",
    "\n",
    "    print(f\"Inference ID: {inference_id}. State: {state}\")\n",
    "\n",
    "    return inference_id, state, image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"createdAt\":\"2023-03-14T18:19:42.337821+00:00\",\"id\":\"2880d417-3372-4c5f-8ccc-22b6a88fb01b\",\"status\":\"queued\"}\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: queued\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: queued\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: queued\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: processing\n",
      "Version ID: 2880d417-3372-4c5f-8ccc-22b6a88fb01b. Status: finished\n"
     ]
    }
   ],
   "source": [
    "# Let's create a custom model so we can fine tune it.\n",
    "model_id = create_model(\"Sample\")\n",
    "\n",
    "# We now upload the images to fine tune this model.\n",
    "upload_image_samples(model_id)\n",
    "\n",
    "# Now it's time to fine tune the model. Notice how I'm continuously \n",
    "# getting the status of the training job and waiting until it's\n",
    "# finished before moving on.\n",
    "version_id, status = queue_training_job(model_id)\n",
    "while status != \"finished\":\n",
    "    time.sleep(10)\n",
    "    version_id, status = get_model_version(model_id, version_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference ID: 3141b41a-a75e-42b2-bd2a-cfba6d7c6434. Status: queued\n",
      "Inference ID: 3141b41a-a75e-42b2-bd2a-cfba6d7c6434. State: queued\n",
      "Inference ID: 3141b41a-a75e-42b2-bd2a-cfba6d7c6434. State: queued\n",
      "Inference ID: 3141b41a-a75e-42b2-bd2a-cfba6d7c6434. State: finished\n",
      "https://dreamtrain.s3.us-west-2.amazonaws.com/image-gen-3141b41a-a75e-42b2-bd2a-cfba6d7c6434/generated_images/0.png\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a fine-tuned version of a model, we can\n",
    "# generate images using it. Notice how I'm using '@me' to \n",
    "# indicate I want pictures similar to the ones we upload to \n",
    "# fine tune this model.\n",
    "inference_id, status = generate_image(\n",
    "    model_id, \n",
    "    prompt=\"A photo of @me wearing black sunglasses\"\n",
    ")\n",
    "while status != \"finished\":\n",
    "    time.sleep(10)\n",
    "    inference_id, status, image = get_inference_job(model_id, inference_id)\n",
    "\n",
    "print(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
